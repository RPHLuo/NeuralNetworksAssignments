{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import clip_ops\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading MNIST dataset\n",
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply stratified sampling\n",
    "X_train ,X_test,y_train,y_test = train_test_split(X,y,train_size = 0.7,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1257 observations with 64 dimensions\n",
      "Train with approximately 238 epochs\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Hyper-parameters\"\"\"\n",
    "batch_size = 300            # Batch size for stochastic gradient descent\n",
    "test_size = batch_size      # Temporary heuristic. In future we'd like to decouple testing from batching\n",
    "num_centr = 150             # Number of \"hidden neurons\" that is number of centroids\n",
    "max_iterations = 1000       # Max number of iterations\n",
    "learning_rate = 5e-2        # Learning rate\n",
    "num_classes = 10            # Number of target classes, 10 for MNIST\n",
    "var_rbf = 225               # What variance do you expect workable for the RBF?\n",
    "\n",
    "#Obtain and proclaim sizes\n",
    "N,D = X_train.shape         \n",
    "Ntest = X_test.shape[0]\n",
    "print('We have %s observations with %s dimensions'%(N,D))\n",
    "\n",
    "#Proclaim the epochs\n",
    "epochs = np.floor(batch_size*max_iterations / N)\n",
    "print('Train with approximately %d epochs' %(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Placeholders for data\n",
    "x = tf.placeholder('float',shape=[batch_size,D],name='input_data')\n",
    "y_ = tf.placeholder(tf.int64, shape=[batch_size], name = 'Ground_truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name cross entropy_loss is illegal; using cross_entropy_loss instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"Hidden_layer\") as scope:\n",
    "  #Centroids and var are the main trainable parameters of the first layer\n",
    "    centroids = tf.Variable(tf.random_uniform([num_centr,D],dtype=tf.float32),name='centroids')\n",
    "    var = tf.Variable(tf.truncated_normal([num_centr],mean=var_rbf,stddev=5,dtype=tf.float32),name='RBF_variance')\n",
    "  \n",
    "  #For now, we collect the distances\n",
    "    exp_list = []\n",
    "    for i in range(num_centr):\n",
    "        exp_list.append(tf.exp((-1*tf.reduce_sum(tf.square(tf.subtract(x,centroids[i,:])),1))/(2*var[i])))\n",
    "        phi = tf.transpose(tf.stack(exp_list))\n",
    "        \n",
    "with tf.name_scope(\"Output_layer\") as scope:\n",
    "    w = tf.Variable(tf.truncated_normal([num_centr,num_classes], stddev=0.1, dtype=tf.float32),name='weight')\n",
    "    bias = tf.Variable( tf.constant(0.1, shape=[num_classes]),name='bias')\n",
    "        \n",
    "    h = tf.matmul(phi,w)+bias\n",
    "    size2 = tf.shape(h)\n",
    "\n",
    "with tf.name_scope(\"Softmax\") as scope:\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=h,labels=y_)\n",
    "    cost = tf.reduce_sum(loss)\n",
    "    loss_summ = tf.summary.scalar(\"cross entropy_loss\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\") as scope:\n",
    "    tvars = tf.trainable_variables()\n",
    "    #We clip the gradients to prevent explosion\n",
    "    grads = tf.gradients(cost, tvars)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    gradients = zip(grads, tvars)\n",
    "    train_step = optimizer.apply_gradients(gradients)\n",
    "#     The following block plots for every trainable variable\n",
    "    numel = tf.constant([[0]])\n",
    "    for gradient, variable in gradients:\n",
    "        if isinstance(gradient, ops.IndexedSlices):\n",
    "            grad_values = gradient.values\n",
    "        else:\n",
    "            grad_values = gradient\n",
    "        numel += tf.reduce_sum(tf.size(variable))\n",
    "        h1 = tf.histogram_summary(variable.name, variable)\n",
    "        h2 = tf.histogram_summary(variable.name + \"/gradients\", grad_values)\n",
    "        h3 = tf.histogram_summary(variable.name + \"/gradient_norm\", clip_ops.global_norm([grad_values]))\n",
    "with tf.name_scope(\"Evaluating\") as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(h,1), y_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    \n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "perf_collect = np.zeros((4,int(np.floor(max_iterations /100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start session\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "WARNING:tensorflow:From /anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Estimated accuracy at iteration 1 of 1000: 0.0833333\n",
      "Estimated accuracy at iteration 101 of 1000: 0.82\n",
      "Estimated accuracy at iteration 201 of 1000: 0.97\n",
      "Estimated accuracy at iteration 301 of 1000: 0.98\n",
      "Estimated accuracy at iteration 401 of 1000: 0.97\n",
      "Estimated accuracy at iteration 501 of 1000: 0.973333\n",
      "Estimated accuracy at iteration 601 of 1000: 0.983333\n",
      "Estimated accuracy at iteration 701 of 1000: 0.976667\n",
      "Estimated accuracy at iteration 801 of 1000: 0.973333\n",
      "Estimated accuracy at iteration 901 of 1000: 0.97\n"
     ]
    }
   ],
   "source": [
    "#Begin Training\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        print('Start session')\n",
    "        writer = tf.summary.FileWriter(\"./log_tb\", sess.graph_def)\n",
    "\n",
    "        step = 0\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "  \n",
    "    for i in range(max_iterations):\n",
    "        batch_ind = np.random.choice(N,batch_size,replace=False)\n",
    "        if i%100 == 1:\n",
    "            #Measure train performance\n",
    "            result = sess.run([cost,accuracy,train_step],feed_dict={x:X_train[batch_ind], y_: y_train[batch_ind]})\n",
    "            perf_collect[0,step] = result[0]\n",
    "            perf_collect[2,step] = result[1]\n",
    "            \n",
    "            #Measure test performance\n",
    "            test_ind = np.random.choice(Ntest,test_size,replace=False)\n",
    "            result = sess.run([cost,accuracy,merged], feed_dict={ x: X_test[test_ind], y_: y_test[test_ind]})\n",
    "            perf_collect[1,step] = result[0]\n",
    "            perf_collect[3,step] = result[1]\n",
    "      \n",
    "            #Write information for Tensorboard\n",
    "            summary_str = result[2]\n",
    "            writer.add_summary(summary_str, i)\n",
    "            writer.flush()  #Don't forget this command! It makes sure Python writes the summaries to the log-file\n",
    "        \n",
    "            #Print intermediate numbers to terminal\n",
    "            acc = result[1]\n",
    "            print(\"Estimated accuracy at iteration %s of %s: %s\" % (i,max_iterations, acc))\n",
    "            step += 1\n",
    "        else:\n",
    "            sess.run(train_step,feed_dict={x:X_train[batch_ind], y_: y_train[batch_ind]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e5769b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0BtjTIyzoDfGmBj3/wEW4n5lXqrf0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128761d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Additional plots\"\"\"\n",
    "plt.figure()\n",
    "plt.plot(perf_collect[2],label = 'Train accuracy')\n",
    "plt.plot(perf_collect[3],label = 'Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(perf_collect[0],label = 'Train cost')\n",
    "plt.plot(perf_collect[1],label = 'Test cost')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the number of teh hidden later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_centr = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name cross entropy_loss is illegal; using cross_entropy_loss instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"Hidden_layer\") as scope:\n",
    "  #Centroids and var are the main trainable parameters of the first layer\n",
    "    centroids = tf.Variable(tf.random_uniform([num_centr,D],dtype=tf.float32),name='centroids')\n",
    "    var = tf.Variable(tf.truncated_normal([num_centr],mean=var_rbf,stddev=5,dtype=tf.float32),name='RBF_variance')\n",
    "  \n",
    "  #For now, we collect the distances\n",
    "    exp_list = []\n",
    "    for i in range(num_centr):\n",
    "        exp_list.append(tf.exp((-1*tf.reduce_sum(tf.square(tf.subtract(x,centroids[i,:])),1))/(2*var[i])))\n",
    "        phi = tf.transpose(tf.stack(exp_list))\n",
    "        \n",
    "with tf.name_scope(\"Output_layer\") as scope:\n",
    "    w = tf.Variable(tf.truncated_normal([num_centr,num_classes], stddev=0.1, dtype=tf.float32),name='weight')\n",
    "    bias = tf.Variable( tf.constant(0.1, shape=[num_classes]),name='bias')\n",
    "    \n",
    "    h = tf.matmul(phi,w)+bias\n",
    "    size2 = tf.shape(h)\n",
    "\n",
    "with tf.name_scope(\"Softmax\") as scope:\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=h,labels=y_)\n",
    "    cost = tf.reduce_sum(loss)\n",
    "    loss_summ = tf.summary.scalar(\"cross entropy_loss\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\") as scope:\n",
    "    tvars = tf.trainable_variables()\n",
    "    #We clip the gradients to prevent explosion\n",
    "    grads = tf.gradients(cost, tvars)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    gradients = zip(grads, tvars)\n",
    "    train_step = optimizer.apply_gradients(gradients)\n",
    "#     The following block plots for every trainable variable\n",
    "\n",
    "    numel = tf.constant([[0]])\n",
    "    for gradient, variable in gradients:\n",
    "        if isinstance(gradient, ops.IndexedSlices):\n",
    "            grad_values = gradient.values\n",
    "        else:\n",
    "            grad_values = gradient\n",
    "        numel += tf.reduce_sum(tf.size(variable))\n",
    "        h1 = tf.histogram_summary(variable.name, variable)\n",
    "        h2 = tf.histogram_summary(variable.name + \"/gradients\", grad_values)\n",
    "        h3 = tf.histogram_summary(variable.name + \"/gradient_norm\", clip_ops.global_norm([grad_values]))\n",
    "with tf.name_scope(\"Evaluating\") as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(h,1), y_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    \n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "# For now, we collect performances in a Numpy array.\n",
    "# In future releases, I hope TensorBoard allows for more\n",
    "# flexibility in plotting\n",
    "perf_collect = np.zeros((4,int(np.floor(max_iterations /100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start session\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "WARNING:tensorflow:From /anaconda3/envs/tfdeeplearning/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Estimated accuracy at iteration 1 of 1000: 0.0966667\n",
      "Estimated accuracy at iteration 101 of 1000: 0.853333\n"
     ]
    }
   ],
   "source": [
    "#Begin Training\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        print('Start session')\n",
    "        writer = tf.summary.FileWriter(\"./log_tb\", sess.graph_def)\n",
    "\n",
    "        step = 0\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "#    #Debugging\n",
    "#    batch_ind = np.random.choice(N,batch_size,replace=False)\n",
    "#    result = sess.run([phi],feed_dict={x:X_train[batch_ind], y_: y_train[batch_ind]})\n",
    "#    print(result[0])\n",
    "    \n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        batch_ind = np.random.choice(N,batch_size,replace=False)\n",
    "        if i%100 == 1:\n",
    "            #Measure train performance\n",
    "            result = sess.run([cost,accuracy,train_step],feed_dict={x:X_train[batch_ind], y_: y_train[batch_ind]})\n",
    "            perf_collect[0,step] = result[0]\n",
    "            perf_collect[2,step] = result[1]\n",
    "            \n",
    "            #Measure test performance\n",
    "            test_ind = np.random.choice(Ntest,test_size,replace=False)\n",
    "            result = sess.run([cost,accuracy,merged], feed_dict={ x: X_test[test_ind], y_: y_test[test_ind]})\n",
    "            perf_collect[1,step] = result[0]\n",
    "            perf_collect[3,step] = result[1]\n",
    "      \n",
    "            #Write information for Tensorboard\n",
    "            summary_str = result[2]\n",
    "            writer.add_summary(summary_str, i)\n",
    "            writer.flush()  #Don't forget this command! It makes sure Python writes the summaries to the log-file\n",
    "            \n",
    "            #Print intermediate numbers to terminal\n",
    "            acc = result[1]\n",
    "            print(\"Estimated accuracy at iteration %s of %s: %s\" % (i,max_iterations, acc))\n",
    "            step += 1\n",
    "        else:\n",
    "            sess.run(train_step,feed_dict={x:X_train[batch_ind], y_: y_train[batch_ind]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Additional plots\"\"\"\n",
    "plt.figure()\n",
    "plt.plot(perf_collect[2],label = 'Train accuracy')\n",
    "plt.plot(perf_collect[3],label = 'Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(perf_collect[0],label = 'Train cost')\n",
    "plt.plot(perf_collect[1],label = 'Test cost')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Hidden_layer\") as scope:\n",
    "  #Centroids and var are the main trainable parameters of the first layer\n",
    "    centroids = tf.Variable(tf.random_uniform([num_centr,D],dtype=tf.float32),name='centroids')\n",
    "    var = tf.Variable(tf.truncated_normal([num_centr],mean=var_rbf,stddev=5,dtype=tf.float32),name='RBF_variance')\n",
    "  \n",
    "  #For now, we collect the distances\n",
    "    exp_list = []\n",
    "    for i in range(num_centr):\n",
    "        exp_list.append(tf.exp((-1*tf.reduce_sum(tf.square(tf.subtract(x,centroids[i,:])),1))/(2*var[i])))\n",
    "        phi = tf.transpose(tf.stack(exp_list))\n",
    "        \n",
    "with tf.name_scope(\"Output_layer\") as scope:\n",
    "    w = tf.Variable(tf.truncated_normal([num_centr,num_classes], stddev=0.1, dtype=tf.float32),name='weight')\n",
    "    bias = tf.Variable( tf.constant(0.1, shape=[num_classes]),name='bias')\n",
    "    \n",
    "    h = tf.matmul(phi,w)+bias\n",
    "    #Adding dropout\n",
    "    h = tf.nn.dropout(h, 0.5) \n",
    "    \n",
    "    size2 = tf.shape(h)\n",
    "\n",
    "with tf.name_scope(\"Softmax\") as scope:\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=h,labels=y_)\n",
    "    cost = tf.reduce_sum(loss)\n",
    "    loss_summ = tf.summary.scalar(\"cross entropy_loss\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\") as scope:\n",
    "    tvars = tf.trainable_variables()\n",
    "    #We clip the gradients to prevent explosion\n",
    "    grads = tf.gradients(cost, tvars)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    gradients = zip(grads, tvars)\n",
    "    train_step = optimizer.apply_gradients(gradients)\n",
    "#     The following block plots for every trainable variable\n",
    "\n",
    "    numel = tf.constant([[0]])\n",
    "    for gradient, variable in gradients:\n",
    "        if isinstance(gradient, ops.IndexedSlices):\n",
    "            grad_values = gradient.values\n",
    "        else:\n",
    "            grad_values = gradient\n",
    "        numel += tf.reduce_sum(tf.size(variable))\n",
    "        h1 = tf.histogram_summary(variable.name, variable)\n",
    "        h2 = tf.histogram_summary(variable.name + \"/gradients\", grad_values)\n",
    "        h3 = tf.histogram_summary(variable.name + \"/gradient_norm\", clip_ops.global_norm([grad_values]))\n",
    "with tf.name_scope(\"Evaluating\") as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(h,1), y_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    \n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "perf_collect = np.zeros((4,int(np.floor(max_iterations /100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin Training\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        print('Start session')\n",
    "        writer = tf.summary.FileWriter(\"./log_tb\", sess.graph_def)\n",
    "\n",
    "        step = 0\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "   \n",
    "    for i in range(max_iterations):\n",
    "        batch_ind = np.random.choice(N,batch_size,replace=False)\n",
    "        if i%100 == 1:\n",
    "            #Measure train performance\n",
    "            result = sess.run([cost,accuracy,train_step],feed_dict={x:X_train[batch_ind], y_: y_train[batch_ind]})\n",
    "            perf_collect[0,step] = result[0]\n",
    "            perf_collect[2,step] = result[1]\n",
    "            \n",
    "            #Measure test performance\n",
    "            test_ind = np.random.choice(Ntest,test_size,replace=False)\n",
    "            result = sess.run([cost,accuracy,merged], feed_dict={ x: X_test[test_ind], y_: y_test[test_ind]})\n",
    "            perf_collect[1,step] = result[0]\n",
    "            perf_collect[3,step] = result[1]\n",
    "      \n",
    "            #Write information for Tensorboard\n",
    "            summary_str = result[2]\n",
    "            writer.add_summary(summary_str, i)\n",
    "            writer.flush()  #Don't forget this command! It makes sure Python writes the summaries to the log-file\n",
    "        \n",
    "            #Print intermediate numbers to terminal\n",
    "            acc = result[1]\n",
    "            print(\"Estimated accuracy at iteration %s of %s: %s\" % (i,max_iterations, acc))\n",
    "            step += 1\n",
    "        else:\n",
    "            sess.run(train_step,feed_dict={x:X_train[batch_ind], y_: y_train[batch_ind]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Additional plots\"\"\"\n",
    "plt.figure()\n",
    "plt.plot(perf_collect[2],label = 'Train accuracy')\n",
    "plt.plot(perf_collect[3],label = 'Test accuracy')\n",
    "plt.legend()\n",
    "plt.title('Dropout- Train vs Test Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(perf_collect[0],label = 'Train cost')\n",
    "plt.plot(perf_collect[1],label = 'Test cost')\n",
    "plt.legend()\n",
    "plt.title('Dropout- Train vs Test Cost')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
